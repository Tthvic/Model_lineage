# Knowledge Infusion Attack

## Overview

This attack tests the robustness of lineage detection by **injecting knowledge from one model into another** model through finetuning. The experiment evaluates how knowledge inheritance affects lineage similarity.

### Attack Scenario

An attacker attempts to create model variants with different degrees of knowledge from a source model, simulating scenarios where:
- Models are finetuned on data generated by other models
- Different amounts of knowledge transfer create different lineage signatures
- Lineage detection should identify increasing similarity with more knowledge infusion

## Experimental Design

### Models

- **Model A** (Knowledge Source): `blakenp--Qwen2.5-1.5B-Policy2`
  - Base: Qwen-2.5-1.5B-Instruct
  - Finetuned with specific policy domain
  
- **Model B** (Target Model): `jaeyong2--Qwen2.5-1.5B-Instruct-Thai-SFT`
  - Base: Qwen-2.5-1.5B-Instruct  
  - Finetuned with Thai language data

### Knowledge Infusion Levels

We create three variants of Model B by finetuning with different subsets of QA data generated by Model A:

| Variant | QA Range | Sample Count | Description |
|---------|----------|--------------|-------------|
| **B1**  | Q1-Q5    | 5 samples    | Low infusion |
| **B2**  | Q6-Q15   | 10 samples   | Medium infusion |
| **B3**  | Q11-Q30  | 20 samples   | High infusion |

### Hypothesis

**More knowledge from Model A → Higher lineage similarity with Model A**

We expect:
- `Similarity(A, B1) < Similarity(A, B2) < Similarity(A, B3)`
- Lineage similarity increases monotonically with knowledge infusion amount

## Pipeline

### Prerequisites

1. **Models**: Download or ensure access to:
   - Qwen-2.5-1.5B-Instruct (base encoder)
   - Model A: `blakenp--Qwen2.5-1.5B-Policy2`
   - Model B: `jaeyong2--Qwen2.5-1.5B-Instruct-Thai-SFT`

2. **Relation Network**: Pre-trained lineage detection model
   - Path: `data/models/llm/relation_network/best_model.pth`
   - Trained on lineage pairs to predict parent-child relationships

3. **QA Data**: Pre-generated QA pairs from Model A
   - Can use ARC Challenge dataset or custom QA data
   - Minimum 30 QA pairs required

### Step-by-Step Execution

#### Quick Start (Recommended)

```bash
cd adaptive_attacks/llm/knowledge_infusion
./run_experiment.sh
```

This script runs all steps sequentially and generates complete results.

#### Manual Execution

##### Step 1: Split QA Data
```bash
python step1_split_data.py
```
- Loads 30 QA pairs from Model A
- Splits into 3 subsets: B1 (5), B2 (10), B3 (20)
- Saves training-formatted data to `data/`

**Output**:
- `data/qa_1_5.jsonl` (B1 training data)
- `data/qa_6_15.jsonl` (B2 training data)
- `data/qa_11_30.jsonl` (B3 training data)
- `data/qa_full_30.jsonl` (testing data)

##### Step 2: Finetune Models
```bash
python step2_finetune_models.py
```
- Finetunes Model B with each QA subset using LoRA
- Creates B1, B2, B3 variants
- Training: 5 epochs, LR=1e-4, LoRA r=8

**Output**:
- `finetuned_models/B1/` (Model B + 5 QA from A)
- `finetuned_models/B2/` (Model B + 10 QA from A)
- `finetuned_models/B3/` (Model B + 20 QA from A)

##### Step 3: Generate Answers
```bash
python step3_generate_answers.py
```
- Generates answers from A, B1, B2, B3 for all 30 test questions
- Saves in JSONL format

**Output**:
- `answers/model_A_answers.jsonl`
- `answers/model_B1_answers.jsonl`
- `answers/model_B2_answers.jsonl`
- `answers/model_B3_answers.jsonl`

##### Step 4: Generate Embeddings
```bash
python step4_generate_embeddings.py
```
- Encodes "Question + Answer" pairs using Qwen-Instruct AutoModel
- Uses attention-mask pooling for sequence representation
- Generates 1536-dim embeddings per QA

**Output**:
- `embeddings/A_embeddings.pt` [30, 1536]
- `embeddings/B1_embeddings.pt` [30, 1536]
- `embeddings/B2_embeddings.pt` [30, 1536]
- `embeddings/B3_embeddings.pt` [30, 1536]

##### Step 5: Compute B-A Differences
```bash
python step5_compute_ba_diff.py
```
- Computes element-wise difference: `B_variant - A`
- Captures knowledge delta between models
- Essential input for lineage relation network

**Output**:
- `ba_embeddings/B1_minus_A.pt` [30, 1536]
- `ba_embeddings/B2_minus_A.pt` [30, 1536]
- `ba_embeddings/B3_minus_A.pt` [30, 1536]

##### Step 6: Compute Lineage Similarity
```bash
python step6_compute_similarity.py
```
- Loads pre-trained relation network
- Computes lineage similarity for each variant
- Generates visualizations and report

**Output**:
- `results/lineage_similarity_results.json`
- `results/lineage_similarity_report.txt`
- `results/lineage_similarity_analysis.png`
- `results/lineage_similarity_heatmap.png`

## Configuration

Edit [config.py](config.py) to customize:

### Model Paths
```python
BASE_INSTRUCT_MODEL = "data/models/llm/Qwen2.5-1.5B/..."
MODEL_A_PATH = "data/models/llm/.../Policy2"
MODEL_B_PATH = "data/models/llm/.../Thai-SFT"
```

### QA Data Splits
```python
QA_SPLITS = {
    'B1': {'range': (0, 5), 'name': 'qa_1_5'},
    'B2': {'range': (5, 15), 'name': 'qa_6_15'},
    'B3': {'range': (10, 30), 'name': 'qa_11_30'}
}
```

### Finetuning Hyperparameters
```python
FINETUNE_CONFIG = {
    'learning_rate': 1e-4,
    'num_epochs': 5,
    'batch_size': 4,
    'lora_r': 8,
    'lora_alpha': 16,
    ...
}
```

### Interpretation

1. **Monotonic Increase**: If `Sim(A,B1) < Sim(A,B2) < Sim(A,B3)`:
   - ✅ Lineage detection correctly identifies knowledge inheritance
   - ✅ More knowledge transfer → stronger lineage signal
   - ✅ Attack demonstrates predictable lineage behavior

2. **Non-Monotonic / Flat**: If similarity does not increase monotonically:
   - ⚠️ Potential issues:
     - Overfitting to specific samples
     - Data quality varies across QA subsets
     - Hyperparameters need tuning for different data sizes
     - Relation network may not capture this attack pattern

## Files Structure

```
adaptive_attacks/llm/knowledge_infusion/
├── config.py                      # Configuration (paths, hyperparameters)
├── README.md                      # This file
├── run_experiment.sh              # One-click execution script
├── step1_split_data.py            # Split QA data
├── step2_finetune_models.py       # Finetune B1, B2, B3
├── step3_generate_answers.py      # Generate model answers
├── step4_generate_embeddings.py   # Encode QA pairs
├── step5_compute_ba_diff.py       # Compute B-A differences
├── step6_compute_similarity.py    # Compute lineage similarity
├── data/                          # QA data splits
├── finetuned_models/              # B1, B2, B3 checkpoints
├── answers/                       # Model answers (JSONL)
├── embeddings/                    # QA embeddings
├── ba_embeddings/                 # B-A difference embeddings
├── results/                       # Similarity scores + visualizations
└── logs/                          # Execution logs
```

## Troubleshooting

### Common Issues

1. **QA data not found**
   ```
   ERROR: QA data file not found: data/qa_from_model_a.jsonl
   ```
   **Solution**: Generate QA data from Model A or use ARC Challenge dataset

2. **Relation model not found**
   ```
   ERROR: Relation model not exists: data/models/llm/relation_network/best_model.pth
   ```
   **Solution**: Train the relation network using `scripts/llm/train_lineage.py`

3. **CUDA out of memory**
   **Solution**: 
   - Reduce `batch_size` in `FINETUNE_CONFIG`
   - Increase `gradient_accumulation_steps`
   - Use smaller models or gradient checkpointing

4. **LoRA merge fails**
   **Solution**: Ensure base model and LoRA adapter are compatible versions
