#!/usr/bin/env python3
"""
Knowledge Infusion Attack Configuration for LLMs
Tests lineage detection robustness by injecting knowledge from one model into another.
"""

import os
from pathlib import Path

# ===== Experiment Description =====
"""
Knowledge Infusion Attack (Adaptive Attack for LLMs)

Scenario:
Test how knowledge inheritance affects lineage similarity by finetuning one model
with QA data generated by another model. This simulates an attacker injecting
knowledge from model A into model B to create variants B1, B2, B3.

Experiment Design:
1. Model A: blakenp--Qwen2.5-1.5B-Policy2 (finetuned from Qwen-Instruct)
2. Model B: jaeyong2--Qwen2.5-1.5B-Instruct-Thai-SFT (finetuned from Qwen-Instruct)

Finetune model B with different subsets of model A's QA data:
- B1: Use QA pairs 1-5 (5 samples)
- B2: Use QA pairs 6-15 (10 samples)
- B3: Use QA pairs 11-30 (20 samples)

Hypothesis: More knowledge from A â†’ Higher lineage similarity with A

Expected Result: Lineage similarity increases with more infused knowledge
"""

# ===== Model Path Configuration =====
# Base instruction model (encoder for embeddings)
BASE_INSTRUCT_MODEL = "data/models/llm/Qwen2.5-1.5B/base_models/Qwen--Qwen2.5-1.5B-Instruct"

# Model A (knowledge source): generates QA data
MODEL_A_PATH = "data/models/llm/Qwen2.5-1.5B/Finetunes/blakenp--Qwen2.5-1.5B-Policy2"
MODEL_A_NAME = "Qwen2.5-1.5B-Policy2"

# Model B (target model): to be infused with A's knowledge
MODEL_B_PATH = "data/models/llm/Qwen2.5-1.5B/Finetunes/jaeyong2--Qwen2.5-1.5B-Instruct-Thai-SFT"
MODEL_B_NAME = "Qwen2.5-1.5B-Thai-SFT"

# ===== Data Path Configuration =====
# QA data generated by Model A (should be pre-generated or use arc_challenge)
QA_DATA_SOURCE = "arc_challenge"  # or path to pre-generated QA data

# ===== Experiment Output Directories =====
EXPERIMENT_DIR = Path("adaptive_attacks/llm/knowledge_infusion")
DATA_DIR = EXPERIMENT_DIR / "data"
MODELS_DIR = EXPERIMENT_DIR / "finetuned_models"
ANSWERS_DIR = EXPERIMENT_DIR / "answers"
EMBEDDINGS_DIR = EXPERIMENT_DIR / "embeddings"
BA_EMBEDDINGS_DIR = EXPERIMENT_DIR / "ba_embeddings"  # B-A difference embeddings
RESULTS_DIR = EXPERIMENT_DIR / "results"
LOGS_DIR = EXPERIMENT_DIR / "logs"

# Create all directories
for dir_path in [DATA_DIR, MODELS_DIR, ANSWERS_DIR, EMBEDDINGS_DIR, 
                 BA_EMBEDDINGS_DIR, RESULTS_DIR, LOGS_DIR]:
    dir_path.mkdir(parents=True, exist_ok=True)

# ===== QA Data Split Configuration =====
# Define how to split QA data for different infusion levels
QA_SPLITS = {
    'B1': {
        'range': (0, 5),      # Questions 1-5 (indices 0-4)
        'name': 'qa_1_5',
        'description': 'Low infusion: 5 QA pairs from Model A'
    },
    'B2': {
        'range': (5, 15),     # Questions 6-15 (indices 5-14)
        'name': 'qa_6_15',
        'description': 'Medium infusion: 10 QA pairs from Model A'
    },
    'B3': {
        'range': (10, 30),    # Questions 11-30 (indices 10-29)
        'name': 'qa_11_30',
        'description': 'High infusion: 20 QA pairs from Model A'
    }
}

# Total QA pairs for testing (all models tested on same set)
TOTAL_QA_PAIRS = 30

# ===== Finetuning Configuration =====
FINETUNE_CONFIG = {
    'learning_rate': 1e-4,
    'num_epochs': 5,
    'batch_size': 4,
    'max_length': 512,
    'gradient_accumulation_steps': 4,
    'warmup_ratio': 0.1,
    'logging_steps': 10,
    'save_steps': 50,
    'eval_steps': 50,
    
    # LoRA configuration
    'use_lora': True,
    'lora_r': 8,
    'lora_alpha': 16,
    'lora_dropout': 0.05,
    'lora_target_modules': ["q_proj", "k_proj", "v_proj", "o_proj"],
}

# ===== Generation Configuration =====
GENERATION_CONFIG = {
    'max_new_tokens': 256,
    'temperature': 0.7,
    'top_p': 0.9,
    'do_sample': True
}

# ===== Embedding Configuration =====
EMBEDDING_CONFIG = {
    'max_length': 512,
    'batch_size': 16,
    'hidden_dim': 1536  # Qwen 1.5B hidden dimension
}

# ===== Lineage Similarity Model =====
# Pre-trained relation network for lineage detection
RELATION_MODEL_PATH = "data/models/llm/relation_network/best_model.pth"

# ===== Expected Results =====
EXPECTED_RESULTS = {
    'B1': {'similarity': '>0.3', 'description': 'Low similarity (5 QA pairs)'},
    'B2': {'similarity': '>0.4', 'description': 'Medium similarity (10 QA pairs)'},
    'B3': {'similarity': '>0.5', 'description': 'High similarity (20 QA pairs)'}
}

# ===== Other Configuration =====
RANDOM_SEED = 42
DEVICE = 'cuda'

# ===== Helper Functions =====
def get_model_variant_name(variant_key):
    """Get the name for a model variant (B1, B2, B3)."""
    return variant_key

def get_model_variant_path(variant_key):
    """Get the save path for a model variant."""
    return MODELS_DIR / variant_key

def get_qa_split_file(variant_key):
    """Get the QA data file for a specific variant."""
    split_name = QA_SPLITS[variant_key]['name']
    return DATA_DIR / f"{split_name}.jsonl"

def get_answers_file(model_name):
    """Get answers file path for a model."""
    return ANSWERS_DIR / f"model_{model_name}_answers.jsonl"

def get_embeddings_file(model_name):
    """Get embeddings file path for a model."""
    return EMBEDDINGS_DIR / f"{model_name}_embeddings.pt"

def get_ba_diff_file(variant_key):
    """Get B-A difference embeddings file."""
    return BA_EMBEDDINGS_DIR / f"{variant_key}_minus_A.pt"

def get_results_file():
    """Get the results file path."""
    return RESULTS_DIR / "lineage_similarity_results.json"
